{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use EvoAug to generate OOD mutated sequences given a reference sequence (DeepSTARR).\n",
    "\n",
    "Mutations:\n",
    "- random shuffle: apply `tf.random.shuffle(seqs)` to seqs\n",
    "- mutagenesis: apply `RandomMutation(mutate_frac=0.25)` to seqs\n",
    "- evoaug: apply list of augmentations with `max_augs_per_seq=2` to seqs\n",
    "\n",
    "For each reference sequence from the DeepSTARR test set, we will generate 5 OOD sequences.\n",
    "\n",
    "OOD sequences will be saved as (5,N,L,4) numpy arrays in an h5 file, where N is the number of DeepSTARR test seqs and L is 249 (DeepSTARR input sequence length). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-18 17:19:51.484976: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-18 17:19:52.213997: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/lib\n",
      "2024-08-18 17:19:52.214062: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/lib\n",
      "2024-08-18 17:19:52.214067: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# import tensorflow.keras as keras\n",
    "import evoaug_tf\n",
    "from evoaug_tf import evoaug, augment \n",
    "import keras\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import sys\n",
    "import yaml\n",
    "import h5py\n",
    "sys.path.append('../code')\n",
    "from utils import load_DeepSTARR_data\n",
    "from model_zoo import DeepSTARR\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seeds\n",
    "tf.random.set_seed(1)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def apply_augment(x, augment_list, hard_aug=True, max_augs_per_seq=2):\n",
    "\n",
    "    if len(x.shape)==2:\n",
    "        x = tf.reshape(x, (1, x.shape[0], x.shape[1]))\n",
    "    \"\"\"Apply augmentations to each sequence in batch, x.\"\"\"\n",
    "    # number of augmentations per sequence\n",
    "    if hard_aug:\n",
    "        batch_num_aug = tf.constant(max_augs_per_seq, dtype=tf.int32)\n",
    "    else:\n",
    "        batch_num_aug = tf.random.uniform(shape=[], minval=1, maxval=max_augs_per_seq+1, dtype=tf.int32)\n",
    "\n",
    "    max_num_aug = len(augment_list)\n",
    "    insert_max = _augment_max_len(augment_list)\n",
    "\n",
    "    # randomly choose which subset of augmentations from augment_list\n",
    "    aug_indices = tf.sort(tf.random.shuffle(tf.range(max_num_aug))[:batch_num_aug])\n",
    "    # apply augmentation combination to sequences\n",
    "    insert_status = True\n",
    "    ind = 0\n",
    "    for augment in augment_list:\n",
    "        augment_condition = tf.reduce_any(tf.equal(tf.constant(ind), aug_indices))\n",
    "        x = tf.cond(augment_condition, lambda: augment(x), lambda: x)\n",
    "        if augment_condition and hasattr(augment, 'insert_max'):\n",
    "            insert_status = False\n",
    "        ind += 1\n",
    "    if insert_status:\n",
    "        if insert_max:\n",
    "            x = _pad_end(x, insert_max)\n",
    "    return x\n",
    "\n",
    "@tf.function\n",
    "def _pad_end(x, insert_max):\n",
    "        \"\"\"Add random DNA padding of length insert_max to the end of each sequence in batch.\"\"\"\n",
    "\n",
    "        N = tf.shape(x)[0]\n",
    "        L = tf.shape(x)[1]\n",
    "        A = tf.cast(tf.shape(x)[2], dtype = tf.float32)\n",
    "        p = tf.ones((A,)) / A\n",
    "        padding = tf.transpose(tf.gather(tf.eye(A), tf.random.categorical(tf.math.log([p] * insert_max), N)), perm=[1,0,2])\n",
    "\n",
    "        half = int(insert_max/2)\n",
    "        x_padded = tf.concat([padding[:,:half,:], x, padding[:,half:,:]], axis=1)\n",
    "        return x_padded\n",
    "    \n",
    "def _augment_max_len(augment_list):\n",
    "    \"\"\"\n",
    "    Determine whether insertions are applied to determine the insert_max,\n",
    "    which will be applied to pad other sequences with random DNA.\n",
    "    Parameters\n",
    "    ----------\n",
    "    augment_list : list\n",
    "        List of augmentations.\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        Value for insert max.\n",
    "    \"\"\"\n",
    "    insert_max = 0\n",
    "    for augment in augment_list:\n",
    "        if hasattr(augment, 'insert_max'):\n",
    "            insert_max = augment.insert_max\n",
    "    return insert_max\n",
    "\n",
    "def shuffle_channels(tensor):\n",
    "    # Get the shape of the input tensor\n",
    "    N, L, C = tf.shape(tensor)[0], tf.shape(tensor)[1], tf.shape(tensor)[2]\n",
    "    \n",
    "    # Create indices for shuffling\n",
    "    indices = tf.range(C)\n",
    "    \n",
    "    # Tile and reshape indices to match the shape of the input tensor\n",
    "    tiled_indices = tf.tile(tf.expand_dims(indices, 0), [N * L, 1])\n",
    "    \n",
    "    # Shuffle the tiled indices\n",
    "    shuffled_indices = tf.random.shuffle(tiled_indices)\n",
    "    \n",
    "    # Reshape the shuffled indices to match the input tensor shape\n",
    "    shuffled_indices = tf.reshape(shuffled_indices, [N, L, C])\n",
    "    \n",
    "    # Use tf.gather with the shuffled indices to reorder the channel axis\n",
    "    shuffled_tensor = tf.gather(tensor, shuffled_indices, batch_dims=2)\n",
    "    \n",
    "    return shuffled_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from h5 file with hierarchical structure\n"
     ]
    }
   ],
   "source": [
    "data = '../data/DeepSTARR_ensemble_NEW/all_data_with_ensemble_metrics_hierarchical.h5'\n",
    "X_train, y_train, X_test, y_test, X_val, y_val = load_DeepSTARR_data(data, std=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-18 17:29:18.541939: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-18 17:29:19.094422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 141 MB memory:  -> device: 0, name: NVIDIA RTX A4000, pci bus id: 0000:41:00.0, compute capability: 8.6\n",
      "2024-08-18 17:29:29.239049: W tensorflow/tsl/framework/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 312.97MiB (rounded to 328170240)requested by op _EagerConst\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2024-08-18 17:29:29.239103: I tensorflow/tsl/framework/bfc_allocator.cc:1034] BFCAllocator dump for GPU_0_bfc\n",
      "2024-08-18 17:29:29.239116: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (256): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-18 17:29:29.239126: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-18 17:29:29.239136: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1024): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-18 17:29:29.239145: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-18 17:29:29.239154: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-18 17:29:29.239163: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-18 17:29:29.239172: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-18 17:29:29.239181: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-18 17:29:29.239190: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-18 17:29:29.239199: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-18 17:29:29.239208: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-18 17:29:29.239217: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-18 17:29:29.239226: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-18 17:29:29.239236: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-18 17:29:29.239245: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-18 17:29:29.239254: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-18 17:29:29.239263: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-18 17:29:29.239285: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-18 17:29:29.239294: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-18 17:29:29.239315: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-18 17:29:29.239324: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-18 17:29:29.239335: I tensorflow/tsl/framework/bfc_allocator.cc:1057] Bin for 312.97MiB was 256.00MiB, Chunk State: \n",
      "2024-08-18 17:29:29.239343: I tensorflow/tsl/framework/bfc_allocator.cc:1095]      Summary of in-use Chunks by size: \n",
      "2024-08-18 17:29:29.239351: I tensorflow/tsl/framework/bfc_allocator.cc:1102] Sum Total of in-use chunks: 0B\n",
      "2024-08-18 17:29:29.239358: I tensorflow/tsl/framework/bfc_allocator.cc:1104] total_region_allocated_bytes_: 0 memory_limit_: 148439040 available bytes: 148439040 curr_region_allocation_bytes_: 148439040\n",
      "2024-08-18 17:29:29.239370: I tensorflow/tsl/framework/bfc_allocator.cc:1110] Stats: \n",
      "Limit:                       148439040\n",
      "InUse:                               0\n",
      "MaxInUse:                            0\n",
      "NumAllocs:                           0\n",
      "MaxAllocSize:                        0\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2024-08-18 17:29:29.239378: W tensorflow/tsl/framework/bfc_allocator.cc:492] <allocator contains no memory>\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# cast as tensor \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X_test_tf \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf2/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/tf2/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "# cast as tensor \n",
    "X_test_tf = tf.cast(X_test, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply random shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "RandomState.permutation() takes no keyword arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_test_random \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mpermutation(X_test, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m)])\n",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_test_random \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermutation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m)])\n",
      "\u001b[0;31mTypeError\u001b[0m: RandomState.permutation() takes no keyword arguments"
     ]
    }
   ],
   "source": [
    "X_test_random = np.stack([np.random.permutation(X_test, axis=1) for _ in range(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 41186, 249, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_random.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply mutagenesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutagenesis = augment.RandomMutation(mutate_frac=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jessica/anaconda3/envs/tf2/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "X_test_mutagenesis = np.stack([mutagenesis(X_test_tf).numpy() for _ in range(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 41186, 249, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_mutagenesis.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply EvoAug\n",
    "\n",
    "Arguments:\n",
    "- `hard_aug=True`\n",
    "- `max_augs_per_seq=2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_list = [augment.RandomDeletion(delete_min=0, delete_max=20),\n",
    "                augment.RandomTranslocationBatch(shift_min=0, shift_max=20),\n",
    "                # augment.RandomNoise(noise_mean=0, noise_std=0.2),\n",
    "                augment.RandomMutation(mutate_frac=0.05)]\n",
    "\n",
    "# X_test_evoaug = np.stack([tf.map_fn(lambda x: apply_augment(x, augment_list), X_test_tf).numpy()[:,0,:,:] for _ in range(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "configfile = '../results/DeepSTARR_ensemble_NEW/config.yaml'\n",
    "config  = yaml.safe_load(open(configfile, 'r'))\n",
    "model = evoaug.RobustModel(DeepSTARR, config=config, input_shape=X_test[0].shape, augment_list=augment_list, max_augs_per_seq=2, hard_aug=True)\n",
    "model.compile(keras.optimizers.Adam(learning_rate=0.001, decay=1e-6), loss='mse') \n",
    "\n",
    "# Create a dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices(X_test_tf)\n",
    "\n",
    "# Batch the dataset\n",
    "batch_size = 1024\n",
    "batched_dataset = dataset.batch(batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over batches\n",
    "X_test_evoaug_list = []\n",
    "for i in range(5):\n",
    "    x_mut_list = []\n",
    "    for batch in batched_dataset:\n",
    "        x_mut = model._apply_augment(batch)\n",
    "        x_mut_list.append(x_mut)\n",
    "    X_test_evoaug_list.append(tf.concat(x_mut_list, axis=0))\n",
    "\n",
    "X_test_evoaug = tf.stack(X_test_evoaug_list).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 41186, 249, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_evoaug.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save data to h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File('../data/DeepSTARR/ood_seqs.h5', 'w')\n",
    "\n",
    "hf.create_dataset('random', data=X_test_random)\n",
    "hf.create_dataset('mutagenesis', data=X_test_mutagenesis)\n",
    "hf.create_dataset('evoaug', data=X_test_evoaug)\n",
    "\n",
    "hf.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
